{"meta":{"title":"Suave's Blog","subtitle":"","description":"","author":"Suave","url":"https://suavess.github.io","root":"/"},"pages":[{"title":"","date":"2022-06-16T02:01:19.362Z","updated":"2022-06-16T02:01:19.362Z","comments":true,"path":"404.html","permalink":"https://suavess.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"我的朋友们","date":"2022-06-16T02:01:19.366Z","updated":"2022-06-16T02:01:19.366Z","comments":true,"path":"friends/index.html","permalink":"https://suavess.github.io/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"","date":"2022-06-16T02:01:19.366Z","updated":"2022-06-16T02:01:19.366Z","comments":true,"path":"about/index.html","permalink":"https://suavess.github.io/about/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2022-06-16T02:01:19.366Z","updated":"2022-06-16T02:01:19.366Z","comments":true,"path":"categories/index.html","permalink":"https://suavess.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-06-16T02:01:19.366Z","updated":"2022-06-16T02:01:19.366Z","comments":true,"path":"mylist/index.html","permalink":"https://suavess.github.io/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-06-16T02:01:19.367Z","updated":"2022-06-16T02:01:19.367Z","comments":true,"path":"tags/index.html","permalink":"https://suavess.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java编译器对'+'的重载","slug":"Java编译器对'+'的重载","date":"2022-06-16T02:03:21.000Z","updated":"2022-06-16T02:34:11.439Z","comments":true,"path":"2022/06/16/Java编译器对'+'的重载/","link":"","permalink":"https://suavess.github.io/2022/06/16/Java%E7%BC%96%E8%AF%91%E5%99%A8%E5%AF%B9'+'%E7%9A%84%E9%87%8D%E8%BD%BD/","excerpt":"","text":"Java中对字符串进行拼接一般有两种方式，通过Stirng.concat()方法进行拼接，或者直接使用+号拼接，一般来说，我们都会使用第二种方式。 有人把Java中使用+拼接字符串的功能理解为运算符重载。其实并不是，Java是不支持运算符重载的。这其实只是Java提供的一个语法糖。 运算符重载：在计算机程序设计中，运算符重载（英语：operator overloading）是多态的一种。运算符重载，就是对已有的运算符重新进行定义，赋予其另一种功能，以适应不同的数据类型。 语法糖：语法糖（Syntactic sugar），也译为糖衣语法，是由英国计算机科学家彼得·兰丁发明的一个术语，指计算机语言中添加的某种语法，这种语法对语言的功能没有影响，但是更方便程序员使用。语法糖让程序更加简洁，有更高的可读性。 这样的一段代码，让我们看看反编译后的结果 使用IDEA直接查看编译后的class文件 通过查看反编译以后的代码，我们可以发现，原来字符串常量在拼接过程中，是将String转成了StringBuilder后，使用其append方法进行处理的。 那么也就是说，Java中的+对字符串的拼接，其实现原理是使用StringBuilder.append。 但是，String的使用+字符串拼接也不全都是基于StringBuilder.append，还有种特殊情况，那就是如果是两个固定的字面量拼接，如： 1String ab = &quot;a&quot; + &quot;b&quot;; 反编译后 这主要是因为两个字符串都是编译期常量，编译期可知，因此编译器会进行常量折叠，直接变成 String s = “ab”。","categories":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/tags/Java/"}]},{"title":"MySQL锁相关（二）","slug":"MySQL锁相关（二）","date":"2022-02-28T02:57:32.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2022/02/28/MySQL锁相关（二）/","link":"","permalink":"https://suavess.github.io/2022/02/28/MySQL%E9%94%81%E7%9B%B8%E5%85%B3%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"Innodb行锁 行锁特点 ：偏向InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 InnoDB 与 MyISAM 的最大不同有两点：一是支持事务；二是 采用了行级锁。 背景事务及其ACID属性事务是由一组SQL语句组成的逻辑处理单元。 事务具有以下4个特性，简称为事务ACID属性。 ACID属性 含义 原子性（Atomicity） 事务是一个原子操作单元，其对数据的修改，要么全部成功，要么全部失败。 一致性（Consistent） 在事务开始和完成时，数据都必须保持一致状态。 隔离性（Isolation） 数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的 “独立” 环境下运行。 持久性（Durable） 事务完成之后，对于数据的修改是永久的。 并发事务处理带来的问题 问题 含义 丢失更新（Lost Update） 当两个或多个事务选择同一行，最初的事务修改的值，会被后面的事务修改的值覆盖。 脏读（Dirty Reads） 当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读（Non-Repeatable Reads） 一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现和以前读出的数据不一致。 幻读（Phantom Reads） 一个事务按照相同的查询条件重新读取以前查询过的数据，却发现其他事务插入了满足其查询条件的新数据。 事务隔离级别为了解决上述提到的事务并发问题，数据库提供一定的事务隔离机制来解决这个问题。数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使用事务在一定程度上“串行化” 进行，这显然与“并发” 是矛盾的。 数据库的隔离级别有4个，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏写、脏读、不可重复读、幻读这几类问题。 隔离级别 丢失更新 脏读 不可重复读 幻读 Read uncommitted × √ √ √ Read committed × × √ √ Repeatable read（默认） × × × √ Serializable × × × × PS ： √ 代表可能出现 ， × 代表不会出现 。 Mysql 的数据库的默认隔离级别为 Repeatable read ， 查看方式： 12345-- MySQL8以前show variables like &#x27;tx_isolation&#x27;;-- MySQL8以后select @@global.transaction_isolation,@@transaction_isolation; InnoDB 的行锁模式InnoDB 实现了以下两种类型的行锁。 共享锁（S）：又称为读锁，简称S锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。 排他锁（X）：又称为写锁，简称X锁，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。 对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)； 对于普通SELECT语句，InnoDB不会加任何锁； 可以通过以下语句显示给记录集加共享锁或排他锁 。 123共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE排他锁（X) ：SELECT * FROM table_name WHERE ... FOR UPDATE （悲观锁） 悲观锁和乐观锁 悲观锁：事务必须排队执行。数据锁住了，不允许并发。（行级锁：select后面添加for update） 乐观锁：支持并发，事务也不需要排队，只不过需要一个版本号。 行锁测试 Session-1 Session-2 关闭自动提交功能 关闭自动提交功能 可以正常的查询出全部的数据 可以正常的查询出全部的数据 查询id 为3的数据 ； 获取id为3的数据 ； 更新id为3的数据，但是不提交； 新id为3 的数据， 出于等待状态 通过commit， 提交事务 解除阻塞，更新正常进行 以上， 操作的都是同一行的数据，接下来，演示不同行的数据 ： 新id为3数据，正常的获取到行锁 ， 执行更新 ； 由于与Session-1 操作不是同一行，获取当前行锁，执行更新； 如果执行了更新语句，会对这一行数据加上排他锁（写锁），提交commit之后，会释放锁。另外一个线程update语句才可以执行解除阻塞状态。前提是两个线程操作同一行数据。 无索引时行锁升级为表锁 如果不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，实际效果跟表锁一样。 查看当前表的索引 ： show index from test_innodb_lock\\G;（加上 \\G 表示将查询结果进行按列打印，可以使每个字段打印到单独的行） Session-1 Session-2 关闭自动提交功能 关闭自动提交功能 执行更新语句 ： 执行更新语句， 但处于阻塞状态： 提交事务： 解除阻塞，执行更新成功 ： 由于 执行更新时 ， name字段本来为varchar类型， 我们是作为数组类型使用，存在类型转换，索引失效，最终行锁变为表锁 ；(字符串类型，在SQL语句使用的时候没有加单引号，导致索引失效，查询没有走索引，进行全表扫描是，索引失效，行锁就升级为表锁) 间隙锁危害 当我们用范围条件，而不是使用相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据进行加锁； 对于键值在条件范围内但并不存在的记录，叫做 “间隙（GAP）” ， InnoDB也会对这个 “间隙” 加锁，这种锁机制就是所谓的 间隙锁（Next-Key锁） 。 示例 ： Session-1 Session-2 关闭自动提交功能 关闭自动提交功能 根据id范围更新数据 插入id为2的记录， 出于阻塞状态 提交事务 由于表数据中不存在id=2的数据，但是id&lt;4的行被加了排他锁，此时，这行数据就被加了间隙锁。无法插入 解除阻塞 ， 执行插入操作 ： 怎样避免间隙锁呢？ 在更新的时候，或者对数据行进行加锁的时候，尽量去缩小条件，使得间隙数据尽量的少，最大程度避免间隙锁的存在。 InnoDB 行锁争用情况1show status like &#x27;innodb_row_lock%&#x27;; Innodb_row_lock_current_waits: 当前正在等待锁定的数量 Innodb_row_lock_time: 从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg:每次等待所花平均时长 Innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花的时间 Innodb_row_lock_waits: 系统启动后到现在总共等待的次数 当等待的次数很高，而且每次等待的时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。 总结 InnoDB存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面带来了性能损耗可能比表锁会更高一些，但是在整体并发处理能力方面要远远优于MyISAM的表锁的。当系统并发量较高的时候，InnoDB的整体性能和MyISAM相比就会有比较明显的优势。 但是，InnoDB的行级锁同样也有其脆弱的一面，当我们使用不当的时候，可能会让InnoDB的整体性能表现不仅不能比MyISAM高，甚至可能会更差。 优化建议： 尽可能让所有数据检索都能通过索引来完成，避免无索引行锁升级为表锁。 合理设计索引，尽量缩小锁的范围 尽可能减少索引条件，及索引范围，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度 尽可使用低级别事务隔离（但是需要业务层面满足需求）","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"行锁","slug":"行锁","permalink":"https://suavess.github.io/tags/%E8%A1%8C%E9%94%81/"}]},{"title":"MySQL锁相关（一）","slug":"MySQL锁相关（一）","date":"2022-02-27T08:07:46.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2022/02/27/MySQL锁相关（一）/","link":"","permalink":"https://suavess.github.io/2022/02/27/MySQL%E9%94%81%E7%9B%B8%E5%85%B3%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"锁分类从对数据操作的粒度分 ： 1） 表锁：操作时，会锁定整个表。 2） 行锁：操作时，会锁定当前操作行。 从对数据操作的类型分： 1） 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响。 2） 写锁（排它锁）：当前操作没有完成之前，它会阻断其他写锁和读锁。 MySQL中的锁相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。下表中罗列出了各存储引擎对锁的支持情况： 存储引擎 表级锁 行级锁 页面锁 MyISAM 支持 不支持 不支持 InnoDB 支持 支持(默认) 不支持 MEMORY 支持 不支持 不支持 BDB 支持 不支持 支持 MySQL这3种锁的特性可大致归纳如下 ： 锁类型 特点 表级锁 偏向MyISAM 存储引擎，开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁 偏向InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web 应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并查询的应用，如一些在线事务处理系统。 MyISAM的表锁MyISAM 存储引擎只支持表锁，这也是MySQL开始几个版本中唯一支持的锁类型。 如何加表锁 MyISAM 在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。 显示加表锁语法： 123加读锁 ： lock table table_name read;加写锁 ： lock table table_name write； 读锁Session-1 ： 1）获得tb_book 表的读锁 1lock table tb_book read; 2） 执行查询操作 1select * from tb_book; 可以正常执行 ， 查询出数据。 Session-2： 3） 执行查询操作 1select * from tb_book; 也可以正常执行，查询出数据。 Session-1： 4）查询未锁定的表 1select name from tb_seller; Session-1查询未锁定的表失败。因为持有了一张tb_book的读锁，并未释放锁。 Session-2： 5）查询未锁定的表 1select name from tb_seller; 可以正常查询出未锁定的表； Session-1 ： 6） 执行插入操作 1insert into tb_book values(null,&#x27;Mysql高级&#x27;,&#x27;2088-01-01&#x27;,&#x27;1&#x27;); 执行插入， 直接报错 ， 由于当前tb_book 获得的是 读锁， 不能执行更新操作。只能读 Session-2 ： 7） 执行插入操作 1insert into tb_book values(null,&#x27;Mysql高级&#x27;,&#x27;2088-01-01&#x27;,&#x27;1&#x27;); 此时会处于等待状态，当在Session-1中释放锁指令 unlock tables 后 ， Session-2中的 inesrt 语句 ， 立即执行 ； 如果对某一张表加了读锁，不会阻塞其它线程的读操作，但是会阻塞其它线程的写操作。 写锁Session-1 : 1）获得tb_book 表的写锁 1lock table tb_book write ; 2）执行查询操作 1select * from tb_book ; 查询操作执行成功；加了写锁可以读。 3）执行更新操作 1update tb_book set name = &#x27;java编程思想（第二版）&#x27; where id = 1; 更新操作执行成功 ；（加了写锁当然可以写） Session-2 : 4）执行查询操作 1select * from tb_book ; 当在Session-1中释放锁指令 unlock tables 后 ， Session-2中的 select 语句 ， 立即执行 ；（因为Session-1线程加的是写锁，写锁是排他锁，会阻断其他线程的读和写操作） 结论锁模式的相互兼容性如表中所示： 由上表可见： 1） 对MyISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求； 2） 对MyISAM 表的写操作，则会阻塞其他用户对同一表的读和写操作； 简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁，则既会阻塞读，又会阻塞写。 此外，MyISAM 的读写锁调度是写优先，这也是MyISAM不适合做写为主的表的存储引擎的原因。因为写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。 查看锁的争用情况1show open tables； In_user : 表当前被查询使用的次数。如果该数为零，则表是打开的，但是当前没有被使用。 Name_locked：表名称是否被锁定。名称锁定用于取消表或对表进行重命名等操作。 1show status like &#x27;Table_locks%&#x27;; Table_locks_immediate ： 指的是能够立即获得表级锁的次数，每立即获取锁，值加1。 Table_locks_waited ： 指的是不能立即获取表级锁而需要等待的次数，每等待一次，该值加1，此值高说明存在着较为严重的表级锁争用情况。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"表锁","slug":"表锁","permalink":"https://suavess.github.io/tags/%E8%A1%A8%E9%94%81/"}]},{"title":"MySQL索引的失效场景","slug":"MySQL索引的失效场景","date":"2022-02-25T02:23:52.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2022/02/25/MySQL索引的失效场景/","link":"","permalink":"https://suavess.github.io/2022/02/25/MySQL%E7%B4%A2%E5%BC%95%E7%9A%84%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/","excerpt":"","text":"索引设置 1. 最左前缀法则 最左前缀法则指的是查询从索引的最左前列开始，并且不跳过索引中的列。 匹配最左前缀法则，where条件中的顺序不影响使用索引，MySQL优化器会自动选择 违反最左前缀法则，此时不走索引 符合最左索引，但中间有跳跃，此时只会走最左边的部分索引，可以看到key_len（即使用的索引长度）是比第一张图中的key_len小的 2. 范围查询右边的列 都走索引时，key_len字段为456 第二个条件使用范围搜索时，此时key_len是304，与只使用两个字段查询的key_len相同，说明后面的data_id字段没有走索引 3.在索引字段上进行运算操作 4.字段类型隐式转换 由于corpid字段是varchar类型，当where条件中不加引号时，mysql会进行隐式转换，此时索引会失效 5.用or分割的字段条件，其中有一个字段未建立索引 corpid为索引字段，而del为非索引字段 6. MySQL优化器判断索引查询更慢 当表中数据较少，或者查询的条件占表中数据的极大部分时，此时索引效率可能不如全表扫描，MySQL会选择全表扫描 7.以%开头的模糊查询 如果只是尾部的模糊查询是不会失效的 下图中使用强制索引是为了演示，因为表中数据较少，mysql判断索引速度不如全表扫描所以默认走了全表扫描 可以使用覆盖索引来解决该问题，即查询的列可以在索引中找到","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"索引失效","slug":"索引失效","permalink":"https://suavess.github.io/tags/%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88/"}]},{"title":"MySQL中的触发器","slug":"MySQL中的触发器","date":"2022-02-24T11:36:53.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2022/02/24/MySQL中的触发器/","link":"","permalink":"https://suavess.github.io/2022/02/24/MySQL%E4%B8%AD%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/","excerpt":"","text":"1. 介绍 触发器是与表有关的数据库对象，指在 insert/update/delete 之前或之后，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性 , 日志记录 , 数据校验等操作 。 使用别名 OLD 和 NEW 来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。（Oracle既有行级触发器，又有语句级触发器） 触发器类型 NEW 和 OLD的使用 INSERT 型触发器 NEW 表示将要或者已经新增的数据 UPDATE 型触发器 OLD 表示修改之前的数据 , NEW 表示将要或已经修改后的数据 DELETE 型触发器 OLD 表示将要或者已经删除的数据 2. 创建触发器2.1 语法结构 :1CREATE TRIGGER trigger_name trigger_time trigger_event ON tb_name FOR EACH ROW trigger_stmt tb_name ：需要建立触发器的表名(只能是永久表，不能对临时表创建触发器) trigger_name ：触发器名称，自行指定 trigger_time：触发时机，取值BEFORE、AFTER trigger_event ：触发事件，INSERT、UPDATE、DELETE trigger_stmt ： 触发程序体，可以是一条SQL语句或是BEGIN和END包含的多条语句 2.2 示例2.2.1 需求1通过触发器记录 emp 表的数据变更日志 , 包含增加, 修改 , 删除 ; 2.2.2 首先创建一张日志表 :12345678create table emp_logs( id int(11) not null auto_increment, operation varchar(20) not null comment &#x27;操作类型, insert/update/delete&#x27;, operate_time datetime not null comment &#x27;操作时间&#x27;, operate_id int(11) not null comment &#x27;操作表的ID&#x27;, operate_params varchar(500) comment &#x27;操作参数&#x27;, primary key(`id`))engine=innodb default charset=utf8; 2.2.3 创建 insert 型触发器，完成插入数据时的日志记录 :1234567891011DELIMITER $create trigger emp_logs_insert_triggerafter insert on emp for each row begin insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,&#x27;insert&#x27;,now(),new.id,concat(&#x27;插入后(id:&#x27;,new.id,&#x27;, name:&#x27;,new.name,&#x27;, age:&#x27;,new.age,&#x27;, salary:&#x27;,new.salary,&#x27;)&#x27;)); end $DELIMITER ; 2.2.4 创建 update 型触发器，完成更新数据时的日志记录 :1234567891011DELIMITER $create trigger emp_logs_update_triggerafter update on emp for each row begin insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,&#x27;update&#x27;,now(),new.id,concat(&#x27;修改前(id:&#x27;,old.id,&#x27;, name:&#x27;,old.name,&#x27;, age:&#x27;,old.age,&#x27;, salary:&#x27;,old.salary,&#x27;) , 修改后(id&#x27;,new.id, &#x27;name:&#x27;,new.name,&#x27;, age:&#x27;,new.age,&#x27;, salary:&#x27;,new.salary,&#x27;)&#x27;)); end $DELIMITER ; 2.2.5 创建delete 行的触发器 , 完成删除数据时的日志记录 :1234567891011DELIMITER $create trigger emp_logs_delete_triggerafter delete on emp for each row begin insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,&#x27;delete&#x27;,now(),old.id,concat(&#x27;删除前(id:&#x27;,old.id,&#x27;, name:&#x27;,old.name,&#x27;, age:&#x27;,old.age,&#x27;, salary:&#x27;,old.salary,&#x27;)&#x27;)); end $DELIMITER ; 2.2.6 测试：123456insert into emp(id,name,age,salary) values(null, &#x27;光明左使&#x27;,30,3500);insert into emp(id,name,age,salary) values(null, &#x27;光明右使&#x27;,33,3200);update emp set age = 39 where id = 3;delete from emp where id = 5; 3. 删除触发器语法结构 : 1drop trigger [schema_name.]trigger_name 如果没有指定 schema_name，默认为当前数据库 。 4. 查看触发器可以通过执行 SHOW TRIGGERS 命令查看触发器的状态、语法等信息。 语法结构 ： 1show triggers ; 5. 总结 优点是可以在数据库层面保证数据的完整性，并且可以少写业务逻辑代码，使用方便。例如记录日志的功能，可以节省极大量的逻辑代码 缺点也很明显，逻辑在数据库层面，应用层调试困难，出现问题难以定位 注意点 如果BEFORE触发器执行失败，SQL无法正确执行。 SQL执行失败时，AFTER型触发器不会触发。 AFTER类型的触发器执行失败，SQL会回滚。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"触发器","slug":"触发器","permalink":"https://suavess.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8/"}]},{"title":"MySQL索引结构","slug":"MySQL索引结构","date":"2022-02-22T02:38:57.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2022/02/22/MySQL索引结构/","link":"","permalink":"https://suavess.github.io/2022/02/22/MySQL%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84/","excerpt":"","text":"索引是在MySQL的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型的。MySQL目前提供了以下4种索引： BTREE 索引 ： 最常见的索引类型，大部分索引都支持 B 树索引。 HASH 索引：只有Memory引擎支持 ， 使用场景简单 。 R-tree 索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。 Full-text （全文索引） ：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从Mysql5.6版本开始支持全文索引。 MyISAM、InnoDB、Memory三种存储引擎对各种索引类型的支持 索引 InnoDB引擎 MyISAM引擎 Memory引擎 BTREE索引 支持 支持 支持 HASH 索引 不支持 不支持 支持 R-tree 索引 不支持 支持 不支持 Full-text 5.6版本之后支持 支持 不支持 我们平常所说的索引，如果没有特别指明，都是指B+树（多路搜索树，并不一定是二叉的）结构组织的索引。其中聚集索引、复合索引、前缀索引、唯一索引默认都是使用 B+tree 索引，统称为 索引。 BTree索引BTree又叫多路平衡搜索树，一颗m叉的BTree特性如下： 树中每个节点最多包含m个孩子。 除根节点与叶子节点外，每个节点至少有[(m/2)]个孩子。 若根节点不是叶子节点，则至少有两个孩子。 所有的叶子节点都在同一层。 每个非叶子节点由n个key与n+1个指针组成，其中[ceil(m/2)-1] &lt;= n &lt;= m-1 以5叉BTree为例，key的数量：公式推导[ceil(m/2)-1] &lt;= n &lt;= m-1。所以 2 &lt;= n &lt;=4 。当n&gt;4时，中间节点分裂到父节点，两边节点分裂。 插入 C N G A H E K Q M F W L T Z D P R X Y S 数据为例。 演变过程如下： 1). 插入前4个字母 C N G A 2). 插入H，n&gt;4，中间元素G字母向上分裂到新的节点 3). 插入E，K，Q不需要分裂 4). 插入M，中间元素M字母向上分裂到父节点G 5). 插入F，W，L，T不需要分裂 6). 插入Z，中间元素T向上分裂到父节点中 7). 插入D，中间元素D向上分裂到父节点中。然后插入P，R，X，Y不需要分裂 8). 最后插入S，NPQR节点n&gt;5，中间节点Q向上分裂，但分裂后父节点DGMT的n&gt;5，中间节点M向上分裂 到此，该BTREE树就已经构建完成了， BTREE树 和 二叉树 相比， 查询数据的效率更高， 因为对于相同的数据量来说，BTREE的层级结构比二叉树小，因此搜索速度快。 B+TREE 结构B+Tree为BTree的变种，B+Tree与BTree的区别为： 1). n叉B+Tree最多含有n个key，而BTree最多含有n-1个key。 2). B+Tree的叶子节点保存所有的key信息，依key大小顺序排列。 3). 所有的非叶子节点都可以看作是key的索引部分。 由于B+Tree只有叶子节点保存key信息，查询任何key都要从root走到叶子。所以B+Tree的查询效率更加稳定。 MySQL中的B+TreeMySql索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能。 MySQL中的 B+Tree 索引结构示意图:","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://suavess.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://suavess.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"8、ElasticSearch索引Mapping映射关系","slug":"8、ElasticSearch索引Mapping映射关系","date":"2021-10-28T02:08:35.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/10/28/8、ElasticSearch索引Mapping映射关系/","link":"","permalink":"https://suavess.github.io/2021/10/28/8%E3%80%81ElasticSearch%E7%B4%A2%E5%BC%95Mapping%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB/","excerpt":"","text":"ElasticSearch中的映射关系类似于关系型数据库中的表结构，用于说明该字段的类型及约束条件 创建一个新的索引1PUT user 创建映射1234567891011121314151617PUT user/_mapping&#123; &quot;properties&quot;: &#123; &quot;name&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true &#125;, &quot;sex&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;tel&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false &#125; &#125;&#125; 查询映射1GET user/_mapping 映射作用 先插入一条数据 123456PUT user/_create/1001&#123; &quot;name&quot;:&quot;小米&quot;, &quot;sex&quot;:&quot;男的&quot;, &quot;tel&quot;:&quot;1111&quot;&#125; 查询name中含有“小”的数据 12345678GET user/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;小&quot; &#125; &#125;&#125; 查询sex含有”男“的数据 12345678GET user/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;男&quot; &#125; &#125;&#125; 可以看到没有返回数据，原因是sex这个字段指定了类型为keyword，而keyword类型的字段不会被分词，因此需要完全匹配上才可以查询出数据 查询sex含有”男的“的数据 12345678GET user/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;男的&quot; &#125; &#125;&#125; 查询电话 12345678GET user/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;tel&quot;:&quot;11&quot; &#125; &#125;&#125; 此时会报错，原因是创建映射时，指定了index为false，所以无法通过这个字段查询数据","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"7、ElasticSearch文档的查询(3)","slug":"7、ElasticSearch文档的查询(3)","date":"2021-10-27T08:56:19.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/10/27/7、ElasticSearch文档的查询(3)/","link":"","permalink":"https://suavess.github.io/2021/10/27/7%E3%80%81ElasticSearch%E6%96%87%E6%A1%A3%E7%9A%84%E6%9F%A5%E8%AF%A2(3)/","excerpt":"","text":"高亮查询12345678910111213GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match_phrase&quot;:&#123; &quot;category&quot; : &quot;为&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;category&quot;:&#123;&#125; &#125; &#125;&#125; 聚合查询聚合查询类似关系型数据库中的 group by，当然还有很多其他的聚合，例如取最大值max、平均值avg等等。 按price字段进行分组： 12345678910GET shopping/_search&#123; &quot;aggs&quot;:&#123; &quot;price_group&quot;:&#123; &quot;terms&quot;:&#123; &quot;field&quot;:&quot;price&quot; &#125; &#125; &#125;&#125; 上述的返回结果会携带原始数据，如果不想携带可以新增一个size的字段 1234567891011GET shopping/_search&#123; &quot;aggs&quot;:&#123; &quot;price_group&quot;:&#123; &quot;terms&quot;:&#123; &quot;field&quot;:&quot;price&quot; &#125; &#125; &#125;, &quot;size&quot;: 0&#125; 对所有手机价格求平均值 1234567891011GET shopping/_search&#123; &quot;aggs&quot;:&#123; &quot;price_avg&quot;:&#123; &quot;avg&quot;:&#123; &quot;field&quot;:&quot;price&quot; &#125; &#125; &#125;, &quot;size&quot;:0&#125;","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"6、ElasticSearch文档的查询(2)","slug":"6、ElasticSearch文档的查询(2)","date":"2021-10-27T08:14:19.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/10/27/6、ElasticSearch文档的查询(2)/","link":"","permalink":"https://suavess.github.io/2021/10/27/6%E3%80%81ElasticSearch%E6%96%87%E6%A1%A3%E7%9A%84%E6%9F%A5%E8%AF%A2(2)/","excerpt":"","text":"多条件查询 假设想找出小米牌子，价格为3999元的。（must相当于数据库的&amp;&amp;） 12345678910111213141516GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:[&#123; &quot;match&quot;:&#123; &quot;category&quot;:&quot;小米&quot; &#125; &#125;,&#123; &quot;match&quot;:&#123; &quot;price&quot;:3999.00 &#125; &#125;] &#125; &#125;&#125; 假设想找出小米和华为的牌子。（should相当于数据库的||） 12345678910111213141516GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;should&quot;:[&#123; &quot;match&quot;:&#123; &quot;category&quot;:&quot;小米&quot; &#125; &#125;,&#123; &quot;match&quot;:&#123; &quot;category&quot;:&quot;华为&quot; &#125; &#125;] &#125;, &#125;&#125; 假设想找出小米和华为的牌子，价格大于4000元的手机。 1234567891011121314151617181920212223242526GET shopping/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;category&quot;: &quot;小米&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;category&quot;: &quot;华为&quot; &#125; &#125; ], &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gt&quot;: 4000 &#125; &#125; &#125; &#125; &#125;&#125; 完全匹配查询即需要完全包含搜索条件的查询，查询条件不做分词处理 12345678GET shopping/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;category&quot;: &quot;小为&quot; &#125; &#125;&#125;","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"5、ElasticSearch文档的查询(1)","slug":"5、ElasticSearch文档的查询(1)","date":"2021-10-27T07:28:09.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/10/27/5、ElasticSearch文档的查询(1)/","link":"","permalink":"https://suavess.github.io/2021/10/27/5%E3%80%81ElasticSearch%E6%96%87%E6%A1%A3%E7%9A%84%E6%9F%A5%E8%AF%A2(1)/","excerpt":"","text":"主键查询1GET shopping/_doc/1 全查询1GET shopping/_search 条件查询通过链接上拼接参数的方式1GET shopping/_search?q=category:华为 PS:不建议将参数拼接在链接上，可能会有乱码问题 通过请求体12345678GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;category&quot;:&quot;华为&quot; &#125; &#125;&#125; 通过请求体查询所有123456GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;&#125; 查询指定字段1234567GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;, &quot;_source&quot;:[&quot;title&quot;]&#125; 分页查询12345678GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;, &quot;from&quot;:0, &quot;size&quot;:1&#125; 查询排序1234567891011GET shopping/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;, &quot;sort&quot;:&#123; &quot;price&quot;:&#123; &quot;order&quot;:&quot;desc&quot; &#125; &#125;&#125;","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"4、ElasticSearch文档的修改","slug":"4、ElasticSearch文档的修改","date":"2021-10-27T05:56:43.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/10/27/4、ElasticSearch文档的修改/","link":"","permalink":"https://suavess.github.io/2021/10/27/4%E3%80%81ElasticSearch%E6%96%87%E6%A1%A3%E7%9A%84%E4%BF%AE%E6%94%B9/","excerpt":"","text":"完全覆盖修改完全覆盖操作是幂等操作，因此可以使用PUT方法 1234567PUT shopping/_doc/1&#123; &quot;title&quot;:&quot;华为手机&quot;, &quot;category&quot;:&quot;华为&quot;, &quot;images&quot;:&quot;http://www.gulixueyuan.com/hw.jpg&quot;, &quot;price&quot;:1999.00&#125; 此时再获取一下 1GET shopping/_doc/1 可以看到整个数据体被完全覆盖了 局部修改123456POST shopping/_upodate/1&#123; &quot;doc&quot;: &#123; &quot;title&quot;:&quot;OPPO手机&quot; &#125;&#125; 此时再获取一遍","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"3、ElasticSearch文档的创建及删除","slug":"3、ElasticSearch文档的创建","date":"2021-10-27T03:16:14.000Z","updated":"2022-06-16T02:01:19.363Z","comments":true,"path":"2021/10/27/3、ElasticSearch文档的创建/","link":"","permalink":"https://suavess.github.io/2021/10/27/3%E3%80%81ElasticSearch%E6%96%87%E6%A1%A3%E7%9A%84%E5%88%9B%E5%BB%BA/","excerpt":"","text":"创建文档创建文档需要使用POST请求，如果用PUT请求则会报错，原因是PUT请求应当为幂等性操作，而不指定id直接创建文档时，会不断生成新的文档，该操作不为幂等操作，因此无法使用PUT请求 1234567PUT shopping/_doc&#123; &quot;title&quot;:&quot;小米手机&quot;, &quot;category&quot;:&quot;小米&quot;, &quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;, &quot;price&quot;:3999.00&#125; 1234567POST shopping/_doc&#123; &quot;title&quot;:&quot;小米手机&quot;, &quot;category&quot;:&quot;小米&quot;, &quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;, &quot;price&quot;:3999.00&#125; PS:创建文档时，如果指定索引不存在，则会自动创建该索引 _id为ElasticSearch自动为该文档生成的id，如果想要自己指定id，则需要在url后面拼接上id 1234567POST shopping/_doc/1&#123; &quot;title&quot;:&quot;小米手机&quot;, &quot;category&quot;:&quot;小米&quot;, &quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;, &quot;price&quot;:3999.00&#125; 指定id后，操作就是幂等操作了，因此理论上可以换成PUT方式请求， 1234567PUT shopping/_doc/1&#123; &quot;title&quot;:&quot;小米手机&quot;, &quot;category&quot;:&quot;小米&quot;, &quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;, &quot;price&quot;:3999.00&#125; 删除文档同理，只要将请求方式改为DELETE即可 1DELETE shopping/_doc/1","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"2、ElasticSearch索引的创建查询及删除","slug":"2、ElasticSearch索引的创建查询及删除","date":"2021-10-27T02:30:25.000Z","updated":"2022-06-16T02:01:19.363Z","comments":true,"path":"2021/10/27/2、ElasticSearch索引的创建查询及删除/","link":"","permalink":"https://suavess.github.io/2021/10/27/2%E3%80%81ElasticSearch%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E8%AF%A2%E5%8F%8A%E5%88%A0%E9%99%A4/","excerpt":"","text":"后续操作均在Kibana的Dev Tools中完成 创建索引创建使用PUT的请求方式 先创建一个名为shopping的索引 1PUT shopping 此时再次调用则会报错 查询索引 查询指定索引 将PUT改为GET即可 1GET shopping 查询所有的索引 加上?v后会展示字段头信息 1GET _cat/indices?v 删除索引与查询指定索引的逻辑一致，将请求方式改为DELETE即可 1DELETE shopping 此时再查询则会返回404 1GET shopping","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"}]},{"title":"1、Docker安装ElasticSearch和Kibana","slug":"1、Docker安装ElasticSearch和Kibana","date":"2021-10-26T13:09:45.000Z","updated":"2022-06-16T02:01:19.363Z","comments":true,"path":"2021/10/26/1、Docker安装ElasticSearch和Kibana/","link":"","permalink":"https://suavess.github.io/2021/10/26/1%E3%80%81Docker%E5%AE%89%E8%A3%85ElasticSearch%E5%92%8CKibana/","excerpt":"","text":"安装ElasticSearch先拉下es的镜像 1docker pull elasticsearch:7.12.0 镜像拉取完毕后新建容器 1docker run --name elasticsearch -p 9200:9200 -d elasticsearch:7.12.0 等es启动完成后，可以在命令行输入 1curl http://127.0.0.1:9200 或者在浏览器中打开http://127.0.0.1:9200这个网址，如果能看到以下信息则说明我们的es是已经安装好了的。 1234567891011121314151617&#123; &quot;name&quot;: &quot;e0c0b0ff715b&quot;, &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;cluster_uuid&quot;: &quot;c42jGCPrRHiGTix4pUl9EQ&quot;, &quot;version&quot;: &#123; &quot;number&quot;: &quot;7.12.0&quot;, &quot;build_flavor&quot;: &quot;default&quot;, &quot;build_type&quot;: &quot;docker&quot;, &quot;build_hash&quot;: &quot;78722783c38caa25a70982b5b042074cde5d3b3a&quot;, &quot;build_date&quot;: &quot;2021-03-18T06:17:15.410153305Z&quot;, &quot;build_snapshot&quot;: false, &quot;lucene_version&quot;: &quot;8.8.0&quot;, &quot;minimum_wire_compatibility_version&quot;: &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot;: &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot;: &quot;You Know, for Search&quot;&#125; 安装IK分词器es自带的分词器对中文分词不是很友好，所以我们下载开源的IK分词器来解决这个问题。首先进入容器，然后进入plugins目录中下载分词器，下载完成后重启es即可。具体步骤如下: 注意：elasticsearch的版本和ik分词器的版本需要保持一致，不然在重启的时候会失败。 123docker exec -it elasticsearch /bin/bashcd /usr/share/elasticsearch/plugins/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.0/elasticsearch-analysis-ik-7.12.0.zip 安装Kibana同样适用docker安装kibana命令如下: 1docker pull kibana:7.12.0 安装完成以后需要启动kibana容器，需要使用--link连接到elasticsearch容器，--link命令的格式为name:alias，即需要绑定的容器名称以及赋予的别名 1docker run --name kibana --link=elasticsearch:es -p 5601:5601 -d kibana:7.12.0 启动后需要修改kibana的配置文件，将连接es的地址修改为创建容器时填入的别名 123docker exec -it elasticsearch /bin/bashcd /usr/share/kibana/config/vi kibana.yml 将elasticsearch.hosts项修改为 [ &quot;http://es:9200&quot; ] 重启kibana后在浏览器中输入kibana的地址即可打开kibana的页面了","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"},{"name":"Docker","slug":"Docker","permalink":"https://suavess.github.io/tags/Docker/"}]},{"title":"MySQL-limit数据丢失问题","slug":"Mysql-limit数据丢失问题","date":"2021-10-26T07:06:42.000Z","updated":"2022-06-16T02:01:19.366Z","comments":true,"path":"2021/10/26/Mysql-limit数据丢失问题/","link":"","permalink":"https://suavess.github.io/2021/10/26/Mysql-limit%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/","excerpt":"","text":"今天在项目中遇到一个很奇怪的bug，前端调接口分页返回数据时，有两条数据在第一页的最后返回了，然后又在第二页的头返回了，本以为是程序的问题，排查了半天最后发现是Mysql的问题。 Mysql表数据 查询流程先尝试查询前二十条数据1SELECT * FROM tb_customer_open_sea WHERE corpid = &#x27;1&#x27; AND del = 0 LIMIT 0,20; 返回结果 可以看到id为2和3的数据丢失了，同时返回了id为21和22的数据，此时再查询第二页的数据时 1SELECT * FROM tb_customer_open_sea WHERE corpid = &#x27;1&#x27; AND del = 0 LIMIT 20,20; 再次返回了id为21和22的数据，这就离谱了，丢了两条数据，难道是没满足where条件吗？于是我去掉了limit试了试 id为2和3的数据出现了….而和刚才那条SQL的区别只是去掉了limit，难道limit还会影响查询结果？？？然后我又在limit的基础上加上了order by 此时返回的数据中包含了2和3，说明是满足条件的，只是返回的顺序不对可能2和3的数据排在了二十条以后，但是为什么第二页也不包含这两条数据呢 于是我explain了一下这两条sql，发现这两条sql唯一的区别就是第一条走了联合索引，第二条没走联合索引，于是我又尝试了让第二条sql走索引 消失的数据又出现了，果然是索引的问题(不用limit 20,9是因为表中一共就29条数据，这样的话就是全表扫描不会走索引了) 总结当使用limit不使用order by时，且查询条件走了普通索引，就可能会按普通索引的顺序返回数据，所以用了limit就尽量加上order by","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://suavess.github.io/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"Java并发-CAS-乐观锁-解析","slug":"Java并发-CAS-乐观锁-解析","date":"2021-05-26T10:05:24.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2021/05/26/Java并发-CAS-乐观锁-解析/","link":"","permalink":"https://suavess.github.io/2021/05/26/Java%E5%B9%B6%E5%8F%91-CAS-%E4%B9%90%E8%A7%82%E9%94%81-%E8%A7%A3%E6%9E%90/","excerpt":"","text":"本文讲解CAS机制，主要是因为最近准备面试题，发现这个问题在面试中出现的频率非常的高，因此把自己学习过程中的一些理解记录下来。 乐观锁与悲观锁 synchronized是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁。 CAS操作的就是乐观锁，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 模拟线程安全问题先看下面的代码，执行结果不言而喻，最终的结果一定是小于预期的1000 123456789101112131415161718192021222324252627282930313233343536/** * 并发时线程安全问题 * * @author Suave * @author 2021/3/5 1:50 下午 */public class Test01 &#123; static int count = 0; public static void main(String[] args) throws InterruptedException &#123; long startTime = System.currentTimeMillis(); int threadSize = 100; CountDownLatch countDownLatch = new CountDownLatch(threadSize); for (int i = 0; i &lt; threadSize; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt; 10; j++) &#123; try &#123; request(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; countDownLatch.countDown(); &#125;).start(); &#125; countDownLatch.await(); long endTime = System.currentTimeMillis(); System.out.printf(&quot;消耗时长: %d, 结果: %d&quot;, endTime - startTime, count); &#125; public static void request() throws InterruptedException &#123; TimeUnit.MILLISECONDS.sleep(5); count++; &#125;&#125; 这段代码线程不安全的具体原因是 count++ 并不是一个原子性的操作，count++实际会经过三个步骤 获取 count 的值，先记为 A A = count 将 A 的值加一，得到B B = A+1 将 B 的值赋给 count count = B 在多线程的情况下，可能会有多个线程同时走到第一步，同时获取到了相同的A 此时新增后将值赋给B就会出现多个线程调用了这个方法结果count只加了一的情况 线程安全问题解决 线程安全的问题可以通过加锁的方式解决，先来试试最常用也最方便的synchronized关键字，即假设每次都会有冲突，一次只允许一个线程进入的悲观锁 12345// 在request方法上面加上synchronized关键字public synchronized static void request() throws InterruptedException &#123; TimeUnit.MILLISECONDS.sleep(5); count++;&#125; ​ 再来运行试一下 ​ 可以看到，执行结果和我们预期的一致，线程已经安全了。 ​ 但是，这个运行效率就很感人了……… 用CAS乐观锁解决 增加一个CAS方法，同时更改request方法，每次赋值的时候去比较一下值是否发生了改变，改变了就重试 123456789101112131415161718192021/** * CAS方法 * * @param expectCount 期望值count * @param newCount 需要给count赋的新值 * @return true 成功 false 失败 */ public static synchronized boolean compareAndSwap(int expectCount, int newCount) &#123; if (count == expectCount) &#123; count = newCount; return true; &#125; return false; &#125; public static void request() throws InterruptedException &#123; TimeUnit.MILLISECONDS.sleep(5); int expectCount; // expectCount返回false时要再获取count的值并重新赋值 while (!compareAndSwap(expectCount=count, expectCount + 1)) &#123;&#125; &#125; 可以看到，执行结果与我们预期的一致，性能也要强于synchronized悲观锁 那么这段乐观锁的代码就一定不会出问题了吗？ CPU执行某一段代码的时候，会先将数据读取到高速缓存中，极端情况下，当该线程将数据读取到高速缓存中时，其他线程更新了主存中的值，此时我们缓存中的值就不准确了 当我们以缓存中的值做CAS操作时，就会与预期值不一致了，因此，还要在 count 属性上加上 volatile 关键字，保证程序的可见性，每次获取该值时都去主存中获取 CAS的缺点当然，CAS也是有缺点的 CPU开销较大在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。 不能保证代码块的原子性CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了。","categories":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/tags/Java/"},{"name":"锁机制","slug":"锁机制","permalink":"https://suavess.github.io/tags/%E9%94%81%E6%9C%BA%E5%88%B6/"}]},{"title":"Java集合类-RandomAccess接口","slug":"Java集合类-RandomAccess接口","date":"2021-04-26T04:59:21.000Z","updated":"2022-06-16T02:01:19.365Z","comments":true,"path":"2021/04/26/Java集合类-RandomAccess接口/","link":"","permalink":"https://suavess.github.io/2021/04/26/Java%E9%9B%86%E5%90%88%E7%B1%BB-RandomAccess%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"发现RandomAccess接口因为面试的时候问到了怎样使一个 ArrayList 变得线程安全 使用老牌的Vetor 使用CopyOnWriteArrayList 使用Collections.syncronizedList()方法传入一个List，会返回一个线程安全的List 答完后引申到Collections.syncronizedList()的实现原理，当时没看过具体实现并未回答上来。复盘时研究了下，发现首先会先判断传过来的List是否实现了RandomAccess接口 RandomAccess接口详解点进Random接口发现该接口并没有任何属性和任何方法 于是查看jdk8官方文档 官方文档写明了，RandomAccess接口主要是一个标记接口，用来注明这个List是否支持随机访问。 ArrayList实现了Random接口而LinkedList并未实现 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;&#125;public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable &#123;&#125; ArrayList底层是数组，占用一片连续的空间，可以通过计算偏移量来直接获取元素，即支持随机访问，此时使用for (int i=0, n=list.size(); i &lt; n; i++){}循环时的速度要快于iterator顺序循环访问 LinkedList底层是双向链表，遍历要按顺序一个元素节点一个元素节点查询下去，此时iterator速度要快于for (int i=0, n=list.size(); i &lt; n; i++){} 性能测试 随机往数组和链表中插入100000个元素，并分别打印遍历时间 遍历结果 总结可以看到ArrayList（即RandomAccess接口标识的类）使用普通for循环遍历速度较快 而LinkedList（即未被RandomAccess接口标识的类）使用迭代器遍历速度远快于普通for遍历 后续遍历时可以根据是否被RandomAccess接口标识选择更优的遍历方式","categories":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://suavess.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"Java中的值传递和引用传递","slug":"Java中的值传递和引用传递","date":"2020-07-26T07:06:05.000Z","updated":"2022-06-16T02:01:19.364Z","comments":true,"path":"2020/07/26/Java中的值传递和引用传递/","link":"","permalink":"https://suavess.github.io/2020/07/26/Java%E4%B8%AD%E7%9A%84%E5%80%BC%E4%BC%A0%E9%80%92%E5%92%8C%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92/","excerpt":"","text":"Java中的参数传递分为值传递和引用传递，基本类型是值传递，封装类是引用传递。 值传递1234567891011public class Test01 &#123; public static void change(int num) &#123; num = 1; &#125; public static void main(String[] args) &#123; int num = 0; change(num); System.out.println(&quot;num=&quot; + num); &#125;&#125; 上面这段代码的输出结果是num=0。 当调用change方法时，jvm实际上是复制了一份参数传入方法中，无论这个复制后的参数怎么变，main方法中的num参数都是不会发生变化的。 从内存分配的角度来看，栈中是有两个变量的。一个是main方法中定义的num，另外一个是在传参时jvm复制的一份num副本，我们就叫它temp。不论temp值怎么改变，num是不会变的。 引用传值1234567891011121314151617181920212223242526public class Test01 &#123; public static void changeAge(Student student) &#123; student.setAge(20); &#125; public static void main(String[] args) &#123; Student student = new Student(); student.setAge(18); changeAge(student); System.out.println(&quot;student.age=&quot; + student.getAge()); &#125; static class Student &#123; int age; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125;&#125; 上面这段代码的输出结果是student.age=20。 main方法new Student时，jvm在堆中分配了一块内存用于存放Student对象。并且在栈中存放一个student对象，值是指向堆中Student对象的地址。 把student变量传入changeAge()方法时，jvm复制了一份student变量。为了便于理解我们叫它temp，temp的值和student是一样的，都是指向堆中Student对象的地址。 也就是说两个指针都指向了堆中Student对象的地址，此时修改的也就是堆中的该对象，因此main中的student对象也发生了变化 特殊的String 按照上面的说法，String不是基本类型，按理来说应该是引用传递 12345678910111213public class Test01 &#123; public static void change(String str) &#123; str = &quot;456&quot;; &#125; public static void main(String[] args) &#123; String str = &quot;123&quot;; change(str); System.out.println(&quot;str = &quot; + str); &#125;&#125; 实际上上面输出的结果是str = 123。 jvm在实例化字符串时会使用字符串常量池，把str作为参数传入change()方法。jvm复制了一份str变量，为了便于理解我们叫它temp。这个时候str和temp都指向字符串常量池中的&quot;123&quot;。 后续给temp重新赋值为&quot;456&quot;，可以理解为在常量池中新建了&quot;456&quot;这个字符串，并将temp指向常量池中的&quot;456&quot;，此时str的指向是没有发生变化的，因此还是&quot;123&quot;。","categories":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/tags/Java/"}]}],"categories":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/categories/Java/"},{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/categories/MySQL/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/categories/ElasticSearch/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://suavess.github.io/tags/Java/"},{"name":"MySQL","slug":"MySQL","permalink":"https://suavess.github.io/tags/MySQL/"},{"name":"行锁","slug":"行锁","permalink":"https://suavess.github.io/tags/%E8%A1%8C%E9%94%81/"},{"name":"表锁","slug":"表锁","permalink":"https://suavess.github.io/tags/%E8%A1%A8%E9%94%81/"},{"name":"索引失效","slug":"索引失效","permalink":"https://suavess.github.io/tags/%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88/"},{"name":"触发器","slug":"触发器","permalink":"https://suavess.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"name":"索引","slug":"索引","permalink":"https://suavess.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://suavess.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://suavess.github.io/tags/ElasticSearch/"},{"name":"Docker","slug":"Docker","permalink":"https://suavess.github.io/tags/Docker/"},{"name":"锁机制","slug":"锁机制","permalink":"https://suavess.github.io/tags/%E9%94%81%E6%9C%BA%E5%88%B6/"},{"name":"集合","slug":"集合","permalink":"https://suavess.github.io/tags/%E9%9B%86%E5%90%88/"}]}